{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "907cbcfe",
   "metadata": {},
   "source": [
    "> **Note:** This notebook does not contain any raw or derived data from the Sleep Heart Health Study (SHHS).  \n",
    "> All cell outputs have been removed to comply with the NSRR data use agreement.  \n",
    "> To reproduce results, please obtain the dataset from [https://sleepdata.org/datasets/shhs](https://sleepdata.org/datasets/shhs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae5834a-9499-4b07-a9e6-330b75a049a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, subprocess, random, pathlib, sys, platform, subprocess, json, textwrap, pathlib, shutil, mne, numpy as np, concurrent.futures as cf, matplotlib.pyplot as plt, tensorflow as tf, seaborn as sns\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from itertools import groupby, islice\n",
    "from tqdm import tqdm\n",
    "from lxml import etree\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, RocCurveDisplay\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve, auc\n",
    "from tensorflow.keras import layers, models, callbacks, mixed_precision, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d56b82-05f9-40b4-a7a3-bcb63485ede6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(cmd):\n",
    "    try:\n",
    "        return subprocess.check_output(cmd, shell=True, text=True).strip()\n",
    "    except Exception:\n",
    "        return \"N/A\"\n",
    "\n",
    "cpu_model = run(\"lscpu | grep -m1 'Model name' | cut -d ':' -f2- | xargs\")\n",
    "if cpu_model == \"N/A\":\n",
    "    cpu_model = run(\"grep -m1 'model name' /proc/cpuinfo | cut -d ':' -f2- | xargs\")\n",
    "\n",
    "info = {\n",
    "    \"Timestamp\"        : datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    \"Host\"             : platform.node(),\n",
    "    \"OS\"               : f\"{platform.system()} {platform.release()}\",\n",
    "    \"Python\"           : platform.python_version(),\n",
    "    \"TensorFlow\"       : tf.__version__,\n",
    "    \"TensorFlow Build\" : tf.sysconfig.get_build_info().get(\"build_type\",\"N/A\"),\n",
    "    \"CUDA Built w/\"    : tf.sysconfig.get_build_info().get(\"cuda_version\",\"N/A\"),\n",
    "    \"cuDNN Built w/\"   : tf.sysconfig.get_build_info().get(\"cudnn_version\",\"N/A\"),\n",
    "    \"Num GPUs visible\" : len(tf.config.experimental.list_physical_devices('GPU')),\n",
    "    \"GPU Name(s)\"      : run(\"nvidia-smi --query-gpu=name --format=csv,noheader\"),\n",
    "    \"GPU Driver\"       : run(\"nvidia-smi --query-gpu=driver_version --format=csv,noheader | head -1\"),\n",
    "    \"CUDA Runtime\"     : run(\"nvcc --version | grep release | awk '{print $6}'\"),\n",
    "    \"cuDNN Runtime\"    : run(\"grep -oP 'CUDNN_MAJOR\\\\s*=\\\\s*\\\\K[0-9]+' /usr/include/cudnn_version.h 2>/dev/null\") + \".\" +\n",
    "                          run(\"grep -oP 'CUDNN_MINOR\\\\s*=\\\\s*\\\\K[0-9]+' /usr/include/cudnn_version.h 2>/dev/null\"),\n",
    "    \"CPU Model\"        : cpu_model,\n",
    "    \"CPU (logical)\"    : os.cpu_count(),\n",
    "    \"CPU (physical)\"   : os.cpu_count()//2 if os.cpu_count() else \"N/A\",\n",
    "    \"RAM (free/total)\" : run(\"free -h | awk '/Mem:/ {print $3\\\"/\\\"$2}'\")\n",
    "}\n",
    "\n",
    "print(\"\\n\".join(f\"{k:<16}: {v}\" for k,v in info.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f227ad-331d-4899-b6be-2748847bd4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = pathlib.Path(\"./blocks_4signale_1Hz\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "if not any(OUT_DIR.glob(\"block_*.npz\")):\n",
    "    DATA_DIR  = pathlib.Path(\"~/data/nsrr/shhs/polysomnography\").expanduser()\n",
    "    EDF_DIR, ANN_DIR = DATA_DIR/\"edfs/shhs2\", DATA_DIR/\"annotations-events-nsrr/shhs2\"\n",
    "    WIN_SEC, STEP_SEC, MIN_APNEA_S = 60, 30, 10\n",
    "    N_WORKER, CHUNK = 16, 600\n",
    "\n",
    "    ORDER = [\"SAO2\", \"HR\", \"THOR RES\", \"ABDO RES\"]\n",
    "    ALIAS = {\n",
    "        \"SAO2\": [\"SAO2\",\"SPO2\",\"SATS\"],\n",
    "        \"HR\":   [\"PR\",\"PULSERATE\",\"HR\"],\n",
    "        \"THOR RES\":[\"THOR RES\",\"THOR\",\"THO\"],\n",
    "        \"ABDO RES\":[\"ABDO RES\",\"ABD\",\"ABDO\"],\n",
    "    }\n",
    "    subj_id = lambda p: p.name.split(\"-\")[1].split(\".\")[0]\n",
    "    contig  = lambda a,n: any(len(list(g))>=n for k,g in groupby(a) if k)\n",
    "\n",
    "    try:\n",
    "        import cupy as xp; to_cpu = xp.asnumpy\n",
    "    except ImportError:\n",
    "        import numpy as xp; to_cpu = lambda a: a\n",
    "\n",
    "    def apnea_events(xml):\n",
    "        ok={\"obstructive apnea\",\"central apnea\",\"mixed apnea\",\"hypopnea\"}\n",
    "        for ev in etree.parse(xml).findall(\".//ScoredEvent\"):\n",
    "            lab=f\"{ev.findtext('EventType','').lower()}|{ev.findtext('EventConcept','').lower()}\"\n",
    "            if any(k in lab for k in ok):\n",
    "                yield float(ev.findtext(\"Start\")), float(ev.findtext(\"Duration\"))\n",
    "\n",
    "    def find_ch(raw, keys):\n",
    "        up={c.upper():c for c in raw.ch_names}\n",
    "        for k in keys:\n",
    "            if k in up: return up[k]\n",
    "\n",
    "    def process_one(edf_path):\n",
    "        sid = subj_id(edf_path)\n",
    "        out_p = OUT_DIR/f\"block_{sid}.npz\"\n",
    "        if out_p.exists(): return sid\n",
    "\n",
    "        raw = mne.io.read_raw_edf(edf_path, preload=True, verbose=False)\n",
    "        chs = [find_ch(raw, ALIAS[c]) for c in ORDER]\n",
    "        if None in chs:\n",
    "            print(f\"{sid}: Kanal fehlt – skip\"); return sid\n",
    "        raw.pick(chs).resample(1, npad=\"auto\")\n",
    "\n",
    "        X = xp.asarray(raw.get_data()).T.astype(xp.float32)\n",
    "        L = X.shape[0]\n",
    "        y = xp.zeros(L, xp.int8)\n",
    "        for s,d in apnea_events(ANN_DIR/f\"shhs2-{sid}-nsrr.xml\"):\n",
    "            y[int(s):int(min(s+d,L))] = 1\n",
    "\n",
    "        X_blk, y_blk = [], []\n",
    "        for t0 in range(0, L-WIN_SEC+1, STEP_SEC):\n",
    "            seg = X[t0:t0+WIN_SEC]\n",
    "            seg = (seg - seg.mean(0)) / (seg.std(0)+1e-8)\n",
    "            X_blk.append(seg)\n",
    "            y_blk.append(int(contig(y[t0:t0+WIN_SEC], MIN_APNEA_S)))\n",
    "\n",
    "        if X_blk:\n",
    "            np.savez_compressed(out_p,\n",
    "                X=to_cpu(xp.stack(X_blk)).astype(np.float16),\n",
    "                y=np.asarray(y_blk, np.int8),\n",
    "                subj_id=np.asarray([sid]*len(y_blk), '<U10'))\n",
    "        return sid\n",
    "\n",
    "    edf_paths = sorted([p for p in EDF_DIR.glob(\"*.edf\")\n",
    "                        if (ANN_DIR/f\"shhs2-{subj_id(p)}-nsrr.xml\").exists()],\n",
    "                       key=lambda p: p.stat().st_size, reverse=True)\n",
    "\n",
    "    def chunked(it, n):\n",
    "        it = iter(it)\n",
    "        while (chunk := list(islice(it, n))):\n",
    "            yield chunk\n",
    "\n",
    "    for bi, batch in enumerate(chunked(edf_paths, CHUNK), 1):\n",
    "        print(f\"\\nBatch {bi} – {len(batch)} Dateien\")\n",
    "        with cf.ProcessPoolExecutor(max_workers=N_WORKER) as pool:\n",
    "            list(tqdm(pool.map(process_one, batch),\n",
    "                      total=len(batch), desc=f\"Batch {bi}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0db4b5-ca02-416f-b00c-2ad1b38e6930",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = pathlib.Path(\"./blocks_4signale_1Hz\")\n",
    "all_npz  = list(DATA_DIR.glob(\"block_*.npz\"))\n",
    "print(\"Found PSG-NPZ:\", len(all_npz))\n",
    "\n",
    "random.shuffle(all_npz)\n",
    "split = int(0.8 * len(all_npz))\n",
    "train_files, val_files = all_npz[:split], all_npz[split:]\n",
    "\n",
    "def npz_to_windows(path):\n",
    "    d = np.load(str(path), mmap_mode=\"r\")\n",
    "    X = d[\"X\"].astype(\"float16\")            # (n_win, 60, 4)\n",
    "    y = d[\"y\"].astype(\"int8\")\n",
    "    for xi, yi in zip(X, y):\n",
    "        yield xi, yi\n",
    "\n",
    "def make_dataset(files, batch=256, shuffle=True):\n",
    "    def gen():\n",
    "        for p in files:\n",
    "            d = np.load(str(p), mmap_mode=\"r\")\n",
    "            X = d[\"X\"].astype(\"float16\")\n",
    "            y = d[\"y\"].astype(\"int8\")\n",
    "            for xi, yi in zip(X, y):\n",
    "                yield xi, yi\n",
    "\n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "            gen,\n",
    "            output_signature=(\n",
    "                tf.TensorSpec((60, 4), tf.float16),\n",
    "                tf.TensorSpec((),      tf.int8)))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(10_000)\n",
    "    return ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "BATCH = 256\n",
    "train_ds = make_dataset(train_files, BATCH, shuffle=True).repeat()\n",
    "val_ds   = make_dataset(val_files,  BATCH, shuffle=False)\n",
    "\n",
    "# Steps per epoch (20 % of all training windows)\n",
    "FRACTION = 0.20\n",
    "tot_train_win = sum(np.load(p, mmap_mode='r')['y'].size for p in train_files)\n",
    "steps_per_epoch = int(FRACTION * tot_train_win / BATCH)\n",
    "val_steps = 1000\n",
    "print(f\"steps/epoch = {steps_per_epoch},  val_steps = {val_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcbdde4-0331-40ac-b960-09648ea949f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "def make_model():\n",
    "    inp = layers.Input(shape=(60,4))\n",
    "    x   = layers.Conv1D(64, 3, padding='same', activation='relu')(inp)\n",
    "    x   = layers.BatchNormalization()(x)\n",
    "    x   = layers.MaxPool1D(2)(x)\n",
    "\n",
    "    x   = layers.Conv1D(128, 3, padding='same', activation='relu')(x)\n",
    "    x   = layers.BatchNormalization()(x)\n",
    "    x   = layers.MaxPool1D(2)(x)\n",
    "\n",
    "    x   = layers.Conv1D(256, 3, padding='same', activation='relu')(x)\n",
    "    x   = layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "    x   = layers.Dense(128, activation='relu')(x)\n",
    "    x   = layers.Dropout(0.3)(x)\n",
    "    out = layers.Dense(1, activation='sigmoid', dtype='float32')(x)\n",
    "    return models.Model(inp, out)\n",
    "\n",
    "model = make_model()\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizers.Adam(1e-3),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[tf.keras.metrics.AUC(name='AUC'),\n",
    "             tf.keras.metrics.Precision(name='Prec'),\n",
    "             tf.keras.metrics.Recall(name='Rec')]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cfca9e-6978-4bfa-a541-4ec11fe9042a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH     = 256\n",
    "FRACTION  = 0.20   # 20 %\n",
    "tot_train = sum(np.load(p, mmap_mode='r')[\"y\"].size for p in train_files)\n",
    "steps_ep  = int(FRACTION * tot_train / BATCH)\n",
    "val_steps = 1000\n",
    "print(f\"steps/epoch = {steps_ep},  val_steps = {val_steps}\")\n",
    "\n",
    "# Mixed Precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "model = make_model()\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(1e-3),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[tf.keras.metrics.AUC(name='AUC'),\n",
    "             tf.keras.metrics.Precision(name='Prec'),\n",
    "             tf.keras.metrics.Recall(name='Rec')]\n",
    ")\n",
    "\n",
    "cb = [\n",
    "    callbacks.ReduceLROnPlateau('val_AUC', factor=0.3, patience=3, mode='max'),\n",
    "    callbacks.EarlyStopping('val_AUC', patience=6,\n",
    "                            restore_best_weights=True, mode='max')\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds.repeat(),\n",
    "    epochs=50,\n",
    "    steps_per_epoch=steps_ep,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps=val_steps,\n",
    "    callbacks=cb\n",
    ")\n",
    "\n",
    "stop_epoch = cb[1].stopped_epoch\n",
    "best_val   = max(history.history[\"val_AUC\"])\n",
    "print(f\"Training stoppte bei Epoche {stop_epoch}.  Best val_AUC = {best_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a62c0ae-3892-4cff-874c-fd76a5c94dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model and history\n",
    "SAVE_DIR = pathlib.Path(\"./apnea_cnn_saved\")\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Native Keras-Container\n",
    "model.save(SAVE_DIR / \"net.keras\", include_optimizer=False)\n",
    "\n",
    "# weights only\n",
    "model.save_weights(SAVE_DIR / \"net.weights.h5\")\n",
    "\n",
    "# TensorFlow-SavedModel\n",
    "model.export(SAVE_DIR / \"saved_model\")\n",
    "\n",
    "# History as JSON\n",
    "import json\n",
    "with open(SAVE_DIR / \"history.json\", \"w\") as f:\n",
    "    json.dump({k: [float(x) for x in v] for k, v in history.history.items()}, f, indent=2)\n",
    "\n",
    "print(\"saved to \", SAVE_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e0fd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = pathlib.Path(\"./apnea_cnn_saved\")\n",
    "\n",
    "model = tf.keras.models.load_model(MODEL_DIR / \"net.keras\",\n",
    "                                   compile=False)\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d2ca16-ef41-447f-bb03-284b605840f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval + confusion\n",
    "\n",
    "# collect labels and scores\n",
    "y_true, y_score = [], []\n",
    "for xb, yb in val_ds.take(val_steps): # val_ds from training\n",
    "    y_true.append(yb.numpy().astype(int))\n",
    "    y_score.append(model.predict(xb, verbose=0).squeeze())\n",
    "\n",
    "y_true = np.concatenate(y_true)\n",
    "y_score= np.concatenate(y_score)\n",
    "y_pred = (y_score >= 0.5).astype(int)\n",
    "\n",
    "roc_auc = roc_auc_score(y_true, y_score)\n",
    "prec, rec, _ = precision_recall_curve(y_true, y_score)\n",
    "pr_auc  = auc(rec, prec)\n",
    "print(classification_report(y_true, y_pred, digits=3))\n",
    "print(f\"ROC-AUC : {roc_auc:.3f}\")\n",
    "print(f\"PR-AUC  : {pr_auc:.3f}\")\n",
    "\n",
    "# Confusion-Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(4,3))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['No Apnea','Apnea'],\n",
    "            yticklabels=['No Apnea','Apnea'])\n",
    "plt.title('Confusion Matrix (validation windows)')\n",
    "plt.xlabel('Predicted'); plt.ylabel('True')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c760c4c-6abf-4704-a62a-f425160e87e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation-ROC\n",
    "fpr_val, tpr_val, _ = roc_curve(y_true, y_score)\n",
    "auc_val = roc_auc_score(y_true, y_score)\n",
    "\n",
    "# SHHS-1-ROC\n",
    "ŷ_shhs  = model.predict(X_shhs, verbose=0)[:, 0]\n",
    "fpr_s, tpr_s, _ = roc_curve(y_shhs, ŷ_shhs)\n",
    "auc_shhs = roc_auc_score(y_shhs, ŷ_shhs)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "RocCurveDisplay(fpr=fpr_val, tpr=tpr_val, roc_auc=auc_val,\n",
    "                estimator_name=\"Validation\").plot(ax=ax)\n",
    "RocCurveDisplay(fpr=fpr_s,   tpr=tpr_s,   roc_auc=auc_shhs,\n",
    "                estimator_name=\"SHHS-1\").plot(ax=ax)\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--', lw=.8) # Random-Baseline\n",
    "ax.set_title(\"ROC-Comparison: Validation vs. SHHS-1\")\n",
    "ax.grid(True)\n",
    "plt.tight_layout();  plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
